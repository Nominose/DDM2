{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DDM² Inference & Evaluation\n",
    "\n",
    "1. 加载训练好的DDM²模型\n",
    "2. 对测试数据进行推理\n",
    "3. 量化评估 (MAE, SSIM, LPIPS)\n",
    "4. 可视化结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import nibabel as nib\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "# ============ 项目路径 ============\n",
    "PROJECT_ROOT = '/path/to/ddm2'  # 修改为你的项目路径\n",
    "sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "import data as Data\n",
    "import model as Model\n",
    "import core.logger as Logger\n",
    "\n",
    "# LPIPS\n",
    "try:\n",
    "    import lpips\n",
    "    HAS_LPIPS = True\n",
    "    print(\"LPIPS 可用\")\n",
    "except ImportError:\n",
    "    HAS_LPIPS = False\n",
    "    print(\"LPIPS 不可用\")\n",
    "\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== 全部配置 ====================\n",
    "\n",
    "config = {\n",
    "    # ---------- 数据路径 ----------\n",
    "    'data': {\n",
    "        'dataroot': '/path/to/noise_data',\n",
    "        'gt_root': '/path/to/gt_data',\n",
    "        'n2n_root': '/path/to/n2n_output',\n",
    "        'bins_file': '/path/to/bins.npy',\n",
    "        'bins_mapped_file': '/path/to/bins_mapped.npy',\n",
    "        'stage2_file': '/path/to/stage2_matched.txt',\n",
    "    },\n",
    "    \n",
    "    # ---------- Checkpoint ----------\n",
    "    'checkpoint': None,  # None = 自动查找最新, 或指定路径\n",
    "    \n",
    "    # ---------- 数据处理 ----------\n",
    "    'preprocess': {\n",
    "        'HU_MIN': -1000.0,\n",
    "        'HU_MAX': 2000.0,\n",
    "        'image_size': 256,\n",
    "        'use_histogram_eq': True,\n",
    "    },\n",
    "    \n",
    "    # ---------- 模型架构 ----------\n",
    "    'model': {\n",
    "        'in_channel': 2,\n",
    "        'out_channel': 1,\n",
    "        'inner_channel': 64,\n",
    "        'channel_mults': [1, 2, 4, 8],\n",
    "        'attn_res': [16],\n",
    "        'res_blocks': 2,\n",
    "        'dropout': 0.2,\n",
    "        'image_size': 256,\n",
    "    },\n",
    "    \n",
    "    # ---------- Beta Schedule ----------\n",
    "    'beta_schedule': {\n",
    "        'schedule': 'linear',\n",
    "        'n_timestep': 2000,\n",
    "        'linear_start': 1e-6,\n",
    "        'linear_end': 1e-2,\n",
    "    },\n",
    "    \n",
    "    # ---------- 推理参数 ----------\n",
    "    'inference': {\n",
    "        'val_volume_idx': 8,  # 测试患者, 'all' 或具体数字\n",
    "        'val_slice_idx': 'all',\n",
    "    },\n",
    "    \n",
    "    # ---------- 评估参数 ----------\n",
    "    'eval': {\n",
    "        'window': [0, 100],  # HU窗口\n",
    "        'display_window': [0, 80],  # 显示窗口\n",
    "    },\n",
    "    \n",
    "    # ---------- GPU ----------\n",
    "    'gpu_id': 0,\n",
    "}\n",
    "\n",
    "# ===================================================\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(config['gpu_id'])\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 加载 HE Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = None\n",
    "bins_mapped = None\n",
    "\n",
    "if config['preprocess']['use_histogram_eq']:\n",
    "    bins_file = config['data']['bins_file']\n",
    "    bins_mapped_file = config['data']['bins_mapped_file']\n",
    "    \n",
    "    if os.path.exists(bins_file) and os.path.exists(bins_mapped_file):\n",
    "        bins = np.load(bins_file).astype(np.float32)\n",
    "        bins_mapped = np.load(bins_mapped_file).astype(np.float32)\n",
    "        print(f\"HE bins 已加载\")\n",
    "        print(f\"  bins: [{bins.min():.1f}, {bins.max():.1f}]\")\n",
    "        print(f\"  bins_mapped: [{bins_mapped.min():.1f}, {bins_mapped.max():.1f}]\")\n",
    "    else:\n",
    "        print(f\"警告: HE bins文件不存在\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 查找 Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_latest_checkpoint():\n",
    "    \"\"\"自动查找最新的checkpoint\"\"\"\n",
    "    exp_path = os.path.join(PROJECT_ROOT, 'experiments')\n",
    "    if not os.path.exists(exp_path):\n",
    "        return None\n",
    "    \n",
    "    latest_dir = None\n",
    "    latest_time = 0\n",
    "    \n",
    "    for d in os.listdir(exp_path):\n",
    "        if d.startswith('ct_denoise_') and not d.endswith('_teacher'):\n",
    "            ckpt = os.path.join(exp_path, d, 'checkpoint', 'latest_gen.pth')\n",
    "            if os.path.exists(ckpt):\n",
    "                mtime = os.path.getmtime(ckpt)\n",
    "                if mtime > latest_time:\n",
    "                    latest_time = mtime\n",
    "                    latest_dir = os.path.join(exp_path, d, 'checkpoint', 'latest')\n",
    "    \n",
    "    return latest_dir\n",
    "\n",
    "checkpoint_path = config['checkpoint']\n",
    "if checkpoint_path is None:\n",
    "    checkpoint_path = find_latest_checkpoint()\n",
    "\n",
    "if checkpoint_path:\n",
    "    print(f\"Checkpoint: {checkpoint_path}\")\n",
    "    # 创建输出目录\n",
    "    output_dir = checkpoint_path.replace('/checkpoint/latest', '/inference')\n",
    "else:\n",
    "    print(\"错误: 未找到checkpoint!\")\n",
    "    output_dir = os.path.join(PROJECT_ROOT, 'inference_results')\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "print(f\"输出目录: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_opt(config, checkpoint_path):\n",
    "    opt = {\n",
    "        'name': 'ddm2',\n",
    "        'gpu_ids': [0],\n",
    "        'distributed': False,\n",
    "        'phase': 'val',\n",
    "        'path': {'resume_state': checkpoint_path},\n",
    "        'model': {\n",
    "            'which_model_G': 'sr3',\n",
    "            'finetune_norm': False,\n",
    "            'unet': config['model'],\n",
    "            'beta_schedule': {'val': config['beta_schedule']},\n",
    "        },\n",
    "    }\n",
    "    return Logger.dict_to_nonedict(opt)\n",
    "\n",
    "opt_model = create_model_opt(config, checkpoint_path)\n",
    "diffusion = Model.create_model(opt_model)\n",
    "diffusion.set_new_noise_schedule(config['beta_schedule'], schedule_phase='val')\n",
    "\n",
    "print(\"模型加载完成!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_opt = {\n",
    "    'name': 'CT_N2N',\n",
    "    'mode': 'N2N',\n",
    "    'dataroot': config['data']['dataroot'],\n",
    "    'gt_root': config['data']['gt_root'],\n",
    "    'n2n_root': config['data']['n2n_root'],\n",
    "    'resolution': config['preprocess']['image_size'],\n",
    "    'HU_MIN': config['preprocess']['HU_MIN'],\n",
    "    'HU_MAX': config['preprocess']['HU_MAX'],\n",
    "    'val_volume_idx': config['inference']['val_volume_idx'],\n",
    "    'val_slice_idx': config['inference']['val_slice_idx'],\n",
    "}\n",
    "\n",
    "if config['preprocess']['use_histogram_eq']:\n",
    "    dataset_opt['bins_file'] = config['data']['bins_file']\n",
    "    dataset_opt['bins_mapped_file'] = config['data']['bins_mapped_file']\n",
    "\n",
    "val_set = Data.create_dataset(dataset_opt, 'val', stage2_file=config['data']['stage2_file'])\n",
    "print(f\"数据集大小: {len(val_set)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 辅助函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_histogram_equalization(img, bins, bins_mapped):\n",
    "    \"\"\"逆向HE: HE空间 → 原始HU\"\"\"\n",
    "    if bins is None or bins_mapped is None:\n",
    "        return img\n",
    "    flat = img.flatten()\n",
    "    indices = np.digitize(flat, bins_mapped) - 1\n",
    "    indices = np.clip(indices, 0, len(bins) - 1)\n",
    "    return bins[indices].reshape(img.shape).astype(np.float32)\n",
    "\n",
    "def calc_metrics(img, ref, vmin, vmax, lpips_fn=None):\n",
    "    \"\"\"计算评估指标\"\"\"\n",
    "    img_c = np.clip(img, vmin, vmax)\n",
    "    ref_c = np.clip(ref, vmin, vmax)\n",
    "    data_range = vmax - vmin\n",
    "    \n",
    "    mae = np.mean(np.abs(img_c - ref_c))\n",
    "    mse = np.mean((img_c - ref_c) ** 2)\n",
    "    psnr = 10 * np.log10(data_range ** 2 / mse) if mse > 0 else float('inf')\n",
    "    ssim_val = ssim(img_c, ref_c, data_range=data_range)\n",
    "    \n",
    "    lpips_val = None\n",
    "    if lpips_fn is not None:\n",
    "        img_norm = (img_c - vmin) / data_range * 2 - 1\n",
    "        ref_norm = (ref_c - vmin) / data_range * 2 - 1\n",
    "        img_t = torch.from_numpy(np.stack([img_norm]*3)[None].astype(np.float32)).to(device)\n",
    "        ref_t = torch.from_numpy(np.stack([ref_norm]*3)[None].astype(np.float32)).to(device)\n",
    "        with torch.no_grad():\n",
    "            lpips_val = lpips_fn(img_t, ref_t).item()\n",
    "    \n",
    "    return {'MAE': mae, 'PSNR': psnr, 'SSIM': ssim_val, 'LPIPS': lpips_val}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HU_MIN = config['preprocess']['HU_MIN']\n",
    "HU_MAX = config['preprocess']['HU_MAX']\n",
    "\n",
    "noisy_list = []\n",
    "first_list = []\n",
    "final_list = []\n",
    "\n",
    "print(f\"开始推理 {len(val_set)} slices...\")\n",
    "\n",
    "for idx in tqdm(range(len(val_set)), desc=\"Inference\"):\n",
    "    sample = val_set[idx]\n",
    "    batch = {k: v.unsqueeze(0) if isinstance(v, torch.Tensor) else v for k, v in sample.items()}\n",
    "    \n",
    "    diffusion.feed_data(batch)\n",
    "    diffusion.test(continous=True)\n",
    "    visuals = diffusion.get_current_visuals()\n",
    "    \n",
    "    all_imgs = visuals['denoised'].numpy()\n",
    "    \n",
    "    # [-1, 1] → [0, 1]\n",
    "    noisy = (all_imgs[0].squeeze() + 1) / 2\n",
    "    first = (all_imgs[1].squeeze() + 1) / 2\n",
    "    final = (all_imgs[-1].squeeze() + 1) / 2\n",
    "    \n",
    "    # [0, 1] → HU\n",
    "    noisy_hu = noisy * (HU_MAX - HU_MIN) + HU_MIN\n",
    "    first_hu = first * (HU_MAX - HU_MIN) + HU_MIN\n",
    "    final_hu = final * (HU_MAX - HU_MIN) + HU_MIN\n",
    "    \n",
    "    # 逆向HE\n",
    "    if bins is not None:\n",
    "        noisy_hu = inverse_histogram_equalization(noisy_hu, bins, bins_mapped)\n",
    "        first_hu = inverse_histogram_equalization(first_hu, bins, bins_mapped)\n",
    "        final_hu = inverse_histogram_equalization(final_hu, bins, bins_mapped)\n",
    "    \n",
    "    noisy_list.append(noisy_hu)\n",
    "    first_list.append(first_hu)\n",
    "    final_list.append(final_hu)\n",
    "\n",
    "print(\"推理完成!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转为volume\n",
    "noisy_vol = np.stack(noisy_list, axis=-1).astype(np.float32)\n",
    "first_vol = np.stack(first_list, axis=-1).astype(np.float32)\n",
    "final_vol = np.stack(final_list, axis=-1).astype(np.float32)\n",
    "\n",
    "print(f\"Volume shape: {first_vol.shape}\")\n",
    "\n",
    "# 保存\n",
    "affine = np.eye(4)\n",
    "nib.save(nib.Nifti1Image(first_vol, affine), os.path.join(output_dir, 'ddm2_first.nii.gz'))\n",
    "nib.save(nib.Nifti1Image(final_vol, affine), os.path.join(output_dir, 'ddm2_final.nii.gz'))\n",
    "print(f\"\\n结果已保存到: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 量化评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载GT\n",
    "gt_root = config['data']['gt_root']\n",
    "gt_path = os.path.join(gt_root, 'gt_img.nii.gz')  # 根据实际路径调整\n",
    "\n",
    "if os.path.exists(gt_path):\n",
    "    gt_data = nib.load(gt_path).get_fdata().astype(np.float32)\n",
    "    print(f\"GT shape: {gt_data.shape}\")\n",
    "    HAS_GT = True\n",
    "else:\n",
    "    print(f\"警告: GT不存在: {gt_path}\")\n",
    "    HAS_GT = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if HAS_GT:\n",
    "    lpips_fn = lpips.LPIPS(net='alex').to(device) if HAS_LPIPS else None\n",
    "    eval_vmin, eval_vmax = config['eval']['window']\n",
    "    \n",
    "    results = {\n",
    "        'Noisy': {'MAE': [], 'PSNR': [], 'SSIM': [], 'LPIPS': []},\n",
    "        'DDM2_First': {'MAE': [], 'PSNR': [], 'SSIM': [], 'LPIPS': []},\n",
    "        'DDM2_Final': {'MAE': [], 'PSNR': [], 'SSIM': [], 'LPIPS': []},\n",
    "    }\n",
    "    \n",
    "    n_slices = min(first_vol.shape[-1], gt_data.shape[-1])\n",
    "    \n",
    "    for s in tqdm(range(n_slices), desc=\"Evaluating\"):\n",
    "        gt_s = gt_data[:, :, s]\n",
    "        \n",
    "        for name, vol in [('Noisy', noisy_vol), ('DDM2_First', first_vol), ('DDM2_Final', final_vol)]:\n",
    "            m = calc_metrics(vol[:, :, s], gt_s, eval_vmin, eval_vmax, lpips_fn)\n",
    "            for k, v in m.items():\n",
    "                if v is not None:\n",
    "                    results[name][k].append(v)\n",
    "    \n",
    "    # 打印结果\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(f\"评估结果 ({n_slices} slices, HU窗口: [{eval_vmin}, {eval_vmax}])\")\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"{'Method':<15} {'MAE ↓':>10} {'PSNR ↑':>10} {'SSIM ↑':>10} {'LPIPS ↓':>10}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    for method in ['Noisy', 'DDM2_First', 'DDM2_Final']:\n",
    "        mae = np.mean(results[method]['MAE'])\n",
    "        psnr = np.mean(results[method]['PSNR'])\n",
    "        ssim_v = np.mean(results[method]['SSIM'])\n",
    "        lpips_v = np.mean(results[method]['LPIPS']) if results[method]['LPIPS'] else float('nan')\n",
    "        print(f\"{method:<15} {mae:>10.4f} {psnr:>10.2f} {ssim_v:>10.4f} {lpips_v:>10.4f}\")\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # 改进百分比\n",
    "    if results['Noisy']['MAE']:\n",
    "        print(\"\\n改进 (vs Noisy):\")\n",
    "        for method in ['DDM2_First', 'DDM2_Final']:\n",
    "            mae_imp = (np.mean(results['Noisy']['MAE']) - np.mean(results[method]['MAE'])) / np.mean(results['Noisy']['MAE']) * 100\n",
    "            ssim_imp = (np.mean(results[method]['SSIM']) - np.mean(results['Noisy']['SSIM'])) / np.mean(results['Noisy']['SSIM']) * 100\n",
    "            print(f\"  {method}: MAE -{mae_imp:.1f}%, SSIM +{ssim_imp:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_slice = first_vol.shape[-1] // 2\n",
    "disp_vmin, disp_vmax = config['eval']['display_window']\n",
    "\n",
    "if HAS_GT:\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "    \n",
    "    # 图像\n",
    "    axes[0, 0].imshow(gt_data[:, :, vis_slice], cmap='gray', vmin=disp_vmin, vmax=disp_vmax)\n",
    "    axes[0, 0].set_title('GT')\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    axes[0, 1].imshow(noisy_vol[:, :, vis_slice], cmap='gray', vmin=disp_vmin, vmax=disp_vmax)\n",
    "    axes[0, 1].set_title('Noisy')\n",
    "    axes[0, 1].axis('off')\n",
    "    \n",
    "    axes[0, 2].imshow(first_vol[:, :, vis_slice], cmap='gray', vmin=disp_vmin, vmax=disp_vmax)\n",
    "    axes[0, 2].set_title('DDM² First')\n",
    "    axes[0, 2].axis('off')\n",
    "    \n",
    "    axes[0, 3].imshow(final_vol[:, :, vis_slice], cmap='gray', vmin=disp_vmin, vmax=disp_vmax)\n",
    "    axes[0, 3].set_title('DDM² Final')\n",
    "    axes[0, 3].axis('off')\n",
    "    \n",
    "    # 差异图\n",
    "    axes[1, 0].axis('off')\n",
    "    \n",
    "    for i, (name, vol) in enumerate([('Noisy', noisy_vol), ('First', first_vol), ('Final', final_vol)]):\n",
    "        diff = vol[:, :, vis_slice] - gt_data[:, :, vis_slice]\n",
    "        axes[1, i+1].imshow(diff, cmap='RdBu', vmin=-30, vmax=30)\n",
    "        axes[1, i+1].set_title(f'{name} - GT\\nMAE={np.mean(np.abs(diff)):.2f}')\n",
    "        axes[1, i+1].axis('off')\n",
    "else:\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "    \n",
    "    axes[0].imshow(noisy_vol[:, :, vis_slice], cmap='gray', vmin=disp_vmin, vmax=disp_vmax)\n",
    "    axes[0].set_title('Noisy')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(first_vol[:, :, vis_slice], cmap='gray', vmin=disp_vmin, vmax=disp_vmax)\n",
    "    axes[1].set_title('DDM² First')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    axes[2].imshow(final_vol[:, :, vis_slice], cmap='gray', vmin=disp_vmin, vmax=disp_vmax)\n",
    "    axes[2].set_title('DDM² Final')\n",
    "    axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, f'visualization_slice{vis_slice}.png'), dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n可视化已保存\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 统计信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Volume 统计 (HU)\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Image':<15} {'Min':>10} {'Max':>10} {'Mean':>10} {'Std':>10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for name, vol in [('Noisy', noisy_vol), ('DDM2 First', first_vol), ('DDM2 Final', final_vol)]:\n",
    "    print(f\"{name:<15} {vol.min():>10.1f} {vol.max():>10.1f} {vol.mean():>10.1f} {vol.std():>10.1f}\")\n",
    "\n",
    "if HAS_GT:\n",
    "    print(f\"{'GT':<15} {gt_data.min():>10.1f} {gt_data.max():>10.1f} {gt_data.mean():>10.1f} {gt_data.std():>10.1f}\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 完成\n",
    "\n",
    "**输出文件:**\n",
    "- `ddm2_first.nii.gz`: 第一步结果\n",
    "- `ddm2_final.nii.gz`: 最终结果\n",
    "- `visualization_sliceX.png`: 可视化"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
