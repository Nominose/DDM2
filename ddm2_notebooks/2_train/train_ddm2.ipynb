{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DDM² Stage 3: Diffusion Model Training\n",
    "\n",
    "**直接调用 `train_diff_model.py`，自动读取 Stage 2 配置**\n",
    "\n",
    "---\n",
    "\n",
    "## 前提条件\n",
    "\n",
    "- Stage 1 已完成（Noise Model checkpoint）\n",
    "- Stage 2 已完成（config 中的 `stage2_file` 和 `use_random_num` 已自动更新）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "工作目录: /host/c/Users/ROG/Documents/GitHub/DDM2\n",
      "配置文件: /host/c/Users/ROG/Documents/GitHub/DDM2/config/ct_denoise.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "# ============ 修改这里 ============\n",
    "PROJECT_ROOT = '/host/c/Users/ROG/Documents/GitHub/DDM2'          # DDM² 项目根目录\n",
    "CONFIG_FILE = 'config/ct_denoise.json'   # 配置文件（Stage 2 已自动更新）\n",
    "# ==================================\n",
    "\n",
    "os.chdir(PROJECT_ROOT)\n",
    "sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "config_path = os.path.join(PROJECT_ROOT, CONFIG_FILE)\n",
    "with open(config_path, 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "print(f\"工作目录: {os.getcwd()}\")\n",
    "print(f\"配置文件: {config_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 数据选择（可覆盖 Stage 2 设置）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据选择配置:\n",
      "  训练 batch: [0, 1, 2, 3, 4]\n",
      "  验证 batch: [5]\n",
      "  Slice 范围: [0, 1000)\n",
      "  random_num: 0 (从 Stage 2 继承)\n",
      "  验证 volume/slice: 0/25\n"
     ]
    }
   ],
   "source": [
    "# ================== 数据选择 ==================\n",
    "# 这些设置默认从 Stage 2 继承，也可以在这里覆盖\n",
    "\n",
    "# --- Batch 选择 ---\n",
    "TRAIN_BATCHES = config['datasets']['train'].get('train_batches', [0, 1, 2, 3, 4])\n",
    "VAL_BATCHES = config['datasets']['train'].get('val_batches', [5])\n",
    "\n",
    "# --- Slice 范围 ---\n",
    "valid_mask = config['datasets']['train'].get('valid_mask', [0, 100])\n",
    "SLICE_START, SLICE_END = valid_mask[0], valid_mask[1]\n",
    "\n",
    "# --- random_num（从 Stage 2 继承）---\n",
    "USE_RANDOM_NUM = config['datasets']['train'].get('use_random_num', 0)\n",
    "\n",
    "# --- 验证可视化用的 volume/slice ---\n",
    "VAL_VOLUME_IDX = 0\n",
    "VAL_SLICE_IDX = 25\n",
    "\n",
    "# ================================================\n",
    "\n",
    "# 更新配置\n",
    "for phase in ['train', 'val']:\n",
    "    config['datasets'][phase]['train_batches'] = TRAIN_BATCHES\n",
    "    config['datasets'][phase]['val_batches'] = VAL_BATCHES\n",
    "    config['datasets'][phase]['valid_mask'] = [SLICE_START, SLICE_END]\n",
    "    config['datasets'][phase]['use_random_num'] = USE_RANDOM_NUM\n",
    "\n",
    "config['datasets']['val']['val_volume_idx'] = VAL_VOLUME_IDX\n",
    "config['datasets']['val']['val_slice_idx'] = VAL_SLICE_IDX\n",
    "\n",
    "print(\"数据选择配置:\")\n",
    "print(f\"  训练 batch: {TRAIN_BATCHES}\")\n",
    "print(f\"  验证 batch: {VAL_BATCHES}\")\n",
    "print(f\"  Slice 范围: [{SLICE_START}, {SLICE_END})\")\n",
    "print(f\"  random_num: {USE_RANDOM_NUM} (从 Stage 2 继承)\")\n",
    "print(f\"  验证 volume/slice: {VAL_VOLUME_IDX}/{VAL_SLICE_IDX}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 训练参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练参数:\n",
      "  迭代次数: 100,000\n",
      "  批大小: 1\n",
      "  学习率: 0.0001\n",
      "  继续训练: 从头开始\n"
     ]
    }
   ],
   "source": [
    "# ================== 训练参数 ==================\n",
    "\n",
    "N_ITER = 100000          # 迭代次数\n",
    "BATCH_SIZE = 1           # 批大小\n",
    "LEARNING_RATE = 1e-4     # 学习率\n",
    "VAL_FREQ = 5000         # 验证频率\n",
    "SAVE_FREQ = 10000        # 保存频率\n",
    "\n",
    "# 继续训练（None = 从头开始）\n",
    "RESUME_STATE = None      # 或 'experiments/xxx/checkpoint/latest'\n",
    "\n",
    "# ==============================================\n",
    "\n",
    "config['train']['n_iter'] = N_ITER\n",
    "config['train']['val_freq'] = VAL_FREQ\n",
    "config['train']['save_checkpoint_freq'] = SAVE_FREQ\n",
    "config['train']['optimizer']['lr'] = LEARNING_RATE\n",
    "config['datasets']['train']['batch_size'] = BATCH_SIZE\n",
    "config['path']['resume_state'] = RESUME_STATE\n",
    "\n",
    "print(\"训练参数:\")\n",
    "print(f\"  迭代次数: {N_ITER:,}\")\n",
    "print(f\"  批大小: {BATCH_SIZE}\")\n",
    "print(f\"  学习率: {LEARNING_RATE}\")\n",
    "print(f\"  继续训练: {RESUME_STATE if RESUME_STATE else '从头开始'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 检查依赖（自动读取）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Stage 3 依赖检查\n",
      "============================================================\n",
      "\n",
      "[Stage 2 文件]\n",
      "  路径: experiments/ct_denoise_teacher/stage2_matched.txt\n",
      "  状态: ✓ 存在 (3450 样本)\n",
      "\n",
      "[random_num 设置]\n",
      "  值: 0\n",
      "  说明: 只用 random_num=0\n",
      "\n",
      "[Excel 数据]\n",
      "  路径: /host/d/file/fixedCT_static_simulation_train_test_gaussian_local.xlsx\n",
      "  状态: ✓\n",
      "\n",
      "============================================================\n",
      "✓ 所有依赖检查通过！\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Stage 3 依赖检查\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "all_ok = True\n",
    "\n",
    "# 1. Stage 2 文件\n",
    "stage2_file = config.get('stage2_file')\n",
    "print(f\"\\n[Stage 2 文件]\")\n",
    "print(f\"  路径: {stage2_file}\")\n",
    "if stage2_file and os.path.exists(stage2_file):\n",
    "    with open(stage2_file, 'r') as f:\n",
    "        n = len(f.readlines())\n",
    "    print(f\"  状态: ✓ 存在 ({n} 样本)\")\n",
    "else:\n",
    "    print(f\"  状态: ✗ 不存在! 请先运行 Stage 2\")\n",
    "    all_ok = False\n",
    "\n",
    "# 2. random_num 设置\n",
    "print(f\"\\n[random_num 设置]\")\n",
    "print(f\"  值: {USE_RANDOM_NUM}\")\n",
    "if USE_RANDOM_NUM == 'both':\n",
    "    print(f\"  说明: 使用两个噪声实现 (N2N 模式)\")\n",
    "else:\n",
    "    print(f\"  说明: 只用 random_num={USE_RANDOM_NUM}\")\n",
    "\n",
    "\n",
    "# 3. 数据文件\n",
    "excel = config['datasets']['train']['dataroot']\n",
    "print(f\"\\n[Excel 数据]\")\n",
    "print(f\"  路径: {excel}\")\n",
    "print(f\"  状态: {'✓' if os.path.exists(excel) else '✗'}\")\n",
    "if not os.path.exists(excel):\n",
    "    all_ok = False\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "if all_ok:\n",
    "    print(\"✓ 所有依赖检查通过！\")\n",
    "else:\n",
    "    print(\"✗ 请修复上述问题\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 运行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "执行: python train_diff_model.py -p train -c /host/c/Users/ROG/Documents/GitHub/DDM2/config/_stage3_temp.json\n",
      "============================================================\n",
      "开始训练...\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# 保存临时配置\n",
    "temp_config = os.path.join(PROJECT_ROOT, 'config', '_stage3_temp.json')\n",
    "with open(temp_config, 'w') as f:\n",
    "    json.dump(config, f, indent=4)\n",
    "\n",
    "cmd = f\"python train_diff_model.py -p train -c {temp_config}\"\n",
    "print(f\"执行: {cmd}\")\n",
    "print(\"=\" * 60)\n",
    "print(\"开始训练...\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.0.1\n",
      "CUDA version: 11.7\n",
      "CUDA available: True\n",
      "export CUDA_VISIBLE_DEVICES=0\n",
      "26-01-02 20:09:53.954 - INFO:   name: ct_denoise_teacher\n",
      "  phase: train\n",
      "  gpu_ids: [0]\n",
      "  path:[\n",
      "    log: experiments/ct_denoise_teacher_260102_200953/logs\n",
      "    tb_logger: experiments/ct_denoise_teacher_260102_200953/tb_logger\n",
      "    results: experiments/ct_denoise_teacher_260102_200953/results\n",
      "    checkpoint: experiments/ct_denoise_teacher_260102_200953/checkpoint\n",
      "    resume_state: None\n",
      "    experiments_root: experiments/ct_denoise_teacher_260102_200953\n",
      "  ]\n",
      "  datasets:[\n",
      "    train:[\n",
      "      name: ct\n",
      "      dataroot: /host/d/file/fixedCT_static_simulation_train_test_gaussian_local.xlsx\n",
      "      data_root: /host/d/file/simulation/\n",
      "      train_batches: [0, 1, 2, 3, 4]\n",
      "      val_batches: [5]\n",
      "      valid_mask: [0, 1000]\n",
      "      slice_range: [30, 80]\n",
      "      phase: train\n",
      "      padding: 3\n",
      "      val_volume_idx: all\n",
      "      val_slice_idx: all\n",
      "      batch_size: 1\n",
      "      in_channel: 1\n",
      "      num_workers: 4\n",
      "      use_shuffle: True\n",
      "      image_size: 512\n",
      "      lr_flip: 0.5\n",
      "      HU_MIN: -1000.0\n",
      "      HU_MAX: 2000.0\n",
      "      histogram_equalization: True\n",
      "      bins_file: /host/d/file/histogram_equalization/bins.npy\n",
      "      bins_mapped_file: /host/d/file/histogram_equalization/bins_mapped.npy\n",
      "      teacher_n2n_root: /host/d/file/pre/noise2noise/pred_images/\n",
      "      teacher_n2n_epoch: 78\n",
      "      use_random_num: 0\n",
      "    ]\n",
      "    val:[\n",
      "      name: ct\n",
      "      dataroot: /host/d/file/fixedCT_static_simulation_train_test_gaussian_local.xlsx\n",
      "      data_root: /host/d/file/simulation/\n",
      "      train_batches: [0, 1, 2, 3, 4]\n",
      "      val_batches: [5]\n",
      "      valid_mask: [0, 1000]\n",
      "      slice_range: [30, 80]\n",
      "      phase: val\n",
      "      padding: 3\n",
      "      val_volume_idx: 0\n",
      "      val_slice_idx: 25\n",
      "      batch_size: 1\n",
      "      in_channel: 1\n",
      "      num_workers: 0\n",
      "      image_size: 512\n",
      "      lr_flip: 0.0\n",
      "      HU_MIN: -1000.0\n",
      "      HU_MAX: 2000.0\n",
      "      histogram_equalization: True\n",
      "      bins_file: /host/d/file/histogram_equalization/bins.npy\n",
      "      bins_mapped_file: /host/d/file/histogram_equalization/bins_mapped.npy\n",
      "      teacher_n2n_root: /host/d/file/pre/noise2noise/pred_images/\n",
      "      teacher_n2n_epoch: 78\n",
      "      use_random_num: 0\n",
      "      data_len: 3\n",
      "    ]\n",
      "  ]\n",
      "  model:[\n",
      "    which_model_G: mri\n",
      "    finetune_norm: False\n",
      "    drop_rate: 0.0\n",
      "    unet:[\n",
      "      in_channel: 1\n",
      "      out_channel: 1\n",
      "      inner_channel: 32\n",
      "      norm_groups: 32\n",
      "      channel_multiplier: [1, 2, 4, 8, 8]\n",
      "      attn_res: [16]\n",
      "      res_blocks: 2\n",
      "      dropout: 0.0\n",
      "      version: v1\n",
      "    ]\n",
      "    beta_schedule:[\n",
      "      train:[\n",
      "        schedule: rev_warmup70\n",
      "        n_timestep: 1000\n",
      "        linear_start: 5e-05\n",
      "        linear_end: 0.01\n",
      "      ]\n",
      "      val:[\n",
      "        schedule: rev_warmup70\n",
      "        n_timestep: 1000\n",
      "        linear_start: 5e-05\n",
      "        linear_end: 0.01\n",
      "      ]\n",
      "    ]\n",
      "    diffusion:[\n",
      "      image_size: 512\n",
      "      channels: 1\n",
      "      conditional: True\n",
      "    ]\n",
      "  ]\n",
      "  train:[\n",
      "    n_iter: 100000\n",
      "    val_freq: 200\n",
      "    save_checkpoint_freq: 10000\n",
      "    print_freq: 100\n",
      "    optimizer:[\n",
      "      type: adam\n",
      "      lr: 0.0001\n",
      "    ]\n",
      "    ema_scheduler:[\n",
      "      step_start_ema: 5000\n",
      "      update_ema_every: 1\n",
      "      ema_decay: 0.9999\n",
      "    ]\n",
      "  ]\n",
      "  noise_model:[\n",
      "    resume_state: None\n",
      "    initial_stage_file: None\n",
      "    drop_rate: 0.0\n",
      "    unet:[\n",
      "      in_channel: 2\n",
      "      out_channel: 1\n",
      "      inner_channel: 32\n",
      "      norm_groups: 32\n",
      "      channel_multiplier: [1, 2, 4, 8, 8]\n",
      "      attn_res: [16]\n",
      "      res_blocks: 2\n",
      "      dropout: 0.0\n",
      "      version: v1\n",
      "    ]\n",
      "    beta_schedule:[\n",
      "      linear_start: 5e-05\n",
      "      linear_end: 0.01\n",
      "    ]\n",
      "    n_iter: 50000\n",
      "    val_freq: 2000\n",
      "    save_checkpoint_freq: 10000\n",
      "    print_freq: 100\n",
      "    optimizer:[\n",
      "      type: adam\n",
      "      lr: 0.0001\n",
      "    ]\n",
      "  ]\n",
      "  stage2_file: experiments/ct_denoise_teacher/stage2_matched.txt\n",
      "  distributed: False\n",
      "\n",
      "26-01-02 20:09:53.955 - INFO: Stage 2 file: experiments/ct_denoise_teacher/stage2_matched.txt\n",
      "[train] Histogram equalization enabled\n",
      "[DEBUG] Phase: train, target_batches: [0, 1, 2, 3, 4]\n",
      "[DEBUG] Original df rows: 200\n",
      "[DEBUG] After batch filter: 168 rows\n",
      "[DEBUG] _build_n2n_pairs: df has 168 rows, 84 groups\n",
      "[DEBUG] use_random_num = both\n",
      "Found 69 N2N pairs (skipped 15 bad samples)\n",
      "[WARNING] Detected offset (50) != config slice_start (30)\n",
      "[train] val_volume_idx: [0, 1, 2, 3, 4]... (total 69)\n",
      "[train] val_slice_idx: [0, 1, 2, 3, 4]... (total 50)\n",
      "[train] n2n_pairs: 69, num_slices: 50\n",
      "[DEBUG] _build_sample_indices: phase=train\n",
      "[DEBUG] n2n_pairs=69, num_slices=50\n",
      "[DEBUG] val_volume_idx=[0, 1, 2, 3, 4]...\n",
      "[DEBUG] val_slice_idx=[0, 1, 2, 3, 4]...\n",
      "[DEBUG] Built 3450 samples\n",
      "[train] CTDataset v2:\n",
      "    pairs=69, slices=50, samples=3450\n",
      "    slice_range: [30, 80)\n",
      "    use_random_num: 两个都用 (N2N)\n",
      "    HU range: [-1000.0, 2000.0]\n",
      "    histogram_equalization: True\n",
      "26-01-02 20:09:56.992 - INFO: CT dataset [ct] is created. Size: 3450\n",
      "26-01-02 20:09:56.993 - INFO: [DEBUG] train_set: 3450 samples\n",
      "26-01-02 20:09:56.993 - INFO: [DEBUG] train_loader: 3450 batches\n",
      "[val] Histogram equalization enabled\n",
      "[DEBUG] Phase: val, target_batches: [5]\n",
      "[DEBUG] Original df rows: 200\n",
      "[DEBUG] After batch filter: 32 rows\n",
      "[DEBUG] _build_n2n_pairs: df has 32 rows, 16 groups\n",
      "[DEBUG] use_random_num = both\n",
      "Found 14 N2N pairs (skipped 2 bad samples)\n",
      "[WARNING] Detected offset (50) != config slice_start (30)\n",
      "[val] val_volume_idx: [0]... (total 1)\n",
      "[val] val_slice_idx: [25]... (total 1)\n",
      "[val] n2n_pairs: 14, num_slices: 50\n",
      "[DEBUG] _build_sample_indices: phase=val\n",
      "[DEBUG] n2n_pairs=14, num_slices=50\n",
      "[DEBUG] val_volume_idx=[0]...\n",
      "[DEBUG] val_slice_idx=[25]...\n",
      "[DEBUG] Built 1 samples\n",
      "[val] CTDataset v2:\n",
      "    pairs=14, slices=50, samples=1\n",
      "    slice_range: [30, 80)\n",
      "    use_random_num: 两个都用 (N2N)\n",
      "    HU range: [-1000.0, 2000.0]\n",
      "    histogram_equalization: True\n",
      "26-01-02 20:09:58.772 - INFO: CT dataset [ct] is created. Size: 1\n",
      "26-01-02 20:09:58.773 - INFO: [DEBUG] val_set: 1 samples\n",
      "26-01-02 20:09:58.773 - INFO: [DEBUG] val_loader: 1 batches\n",
      "26-01-02 20:09:58.774 - INFO: Initial Dataset Finished\n",
      "dropout 0.0 encoder dropout 0.0\n",
      "dropout 0.0 encoder dropout 0.0\n",
      "New beta scheduler set! rev_warmup70\n",
      "26-01-02 20:10:00.742 - INFO: Initialization method [orthogonal]\n",
      "s2s noise activated!\n",
      "New beta scheduler set! rev_warmup70\n",
      "Optimizing: 337 params\n",
      "26-01-02 20:10:01.558 - INFO: [DDM2] is created.\n",
      "26-01-02 20:10:01.559 - INFO: Initial Model Finished\n",
      "26-01-02 20:10:01.560 - INFO: Training config: n_iter=100000, val_freq=200, print_freq=100, save_freq=10000\n",
      "26-01-02 20:10:33.660 - INFO: <epoch:  1, iter:     100> l_pix: 5.8274e-02 \n",
      "26-01-02 20:10:51.915 - INFO: <epoch:  1, iter:     200> l_pix: 1.9952e-02 \n",
      "26-01-02 20:10:51.916 - INFO: \n",
      "26-01-02 20:10:51.916 - INFO: ============================================================\n",
      "26-01-02 20:10:51.917 - INFO: VALIDATION START at step 200\n",
      "26-01-02 20:10:51.918 - INFO: ============================================================\n",
      "26-01-02 20:10:51.918 - INFO: Result path: experiments/ct_denoise_teacher_260102_200953/results/1\n",
      "New beta scheduler set! rev_warmup70\n",
      "26-01-02 20:10:52.066 - INFO: Processing validation sample 1/1\n",
      "\n",
      "sampling loop time step:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "sampling loop time step: 100%|██████████| 1/1 [00:05<00:00,  5.91s/it]\n",
      "sampling loop time step: 100%|██████████| 1/1 [00:05<00:00,  5.91s/it]\n",
      "26-01-02 20:10:57.982 - INFO:   Visuals keys: ['denoised', 'X']\n",
      "26-01-02 20:10:57.983 - INFO:   Denoised tensor shape: torch.Size([3, 1, 512, 512])\n",
      "26-01-02 20:10:58.002 - INFO:   Denoised img shape: (1544, 516, 3), range: [0.000, 0.815]\n",
      "26-01-02 20:10:58.004 - INFO:   Input img shape: (512, 512, 1), range: [0.067, 0.788]\n",
      "26-01-02 20:10:58.204 - INFO:   Saved: experiments/ct_denoise_teacher_260102_200953/results/1/200_1_denoised.png\n",
      "26-01-02 20:10:58.205 - INFO: ============================================================\n",
      "26-01-02 20:10:58.206 - INFO: VALIDATION END - saved 1 images to experiments/ct_denoise_teacher_260102_200953/results/1\n",
      "26-01-02 20:10:58.207 - INFO: ============================================================\n",
      "26-01-02 20:10:58.207 - INFO: \n",
      "New beta scheduler set! rev_warmup70\n",
      "26-01-02 20:11:17.019 - INFO: <epoch:  1, iter:     300> l_pix: 1.7696e-02 \n",
      "26-01-02 20:11:36.145 - INFO: <epoch:  1, iter:     400> l_pix: 1.7660e-02 \n",
      "26-01-02 20:11:36.146 - INFO: \n",
      "26-01-02 20:11:36.146 - INFO: ============================================================\n",
      "26-01-02 20:11:36.147 - INFO: VALIDATION START at step 400\n",
      "26-01-02 20:11:36.147 - INFO: ============================================================\n",
      "26-01-02 20:11:36.148 - INFO: Result path: experiments/ct_denoise_teacher_260102_200953/results/1\n",
      "New beta scheduler set! rev_warmup70\n",
      "26-01-02 20:11:36.225 - INFO: Processing validation sample 1/1\n",
      "\n",
      "sampling loop time step:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "sampling loop time step: 100%|██████████| 1/1 [00:00<00:00, 18.16it/s]\n",
      "26-01-02 20:11:36.484 - INFO:   Visuals keys: ['denoised', 'X']\n",
      "26-01-02 20:11:36.485 - INFO:   Denoised tensor shape: torch.Size([3, 1, 512, 512])\n",
      "26-01-02 20:11:36.496 - INFO:   Denoised img shape: (1544, 516, 3), range: [0.000, 0.788]\n",
      "26-01-02 20:11:36.497 - INFO:   Input img shape: (512, 512, 1), range: [0.067, 0.788]\n",
      "26-01-02 20:11:36.680 - INFO:   Saved: experiments/ct_denoise_teacher_260102_200953/results/1/400_1_denoised.png\n",
      "26-01-02 20:11:36.681 - INFO: ============================================================\n",
      "26-01-02 20:11:36.682 - INFO: VALIDATION END - saved 1 images to experiments/ct_denoise_teacher_260102_200953/results/1\n",
      "26-01-02 20:11:36.682 - INFO: ============================================================\n",
      "26-01-02 20:11:36.683 - INFO: \n",
      "New beta scheduler set! rev_warmup70\n",
      "26-01-02 20:11:55.517 - INFO: <epoch:  1, iter:     500> l_pix: 6.4981e-03 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 运行训练\u001b[39;00m\n\u001b[1;32m      2\u001b[0m process \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mPopen(\n\u001b[1;32m      3\u001b[0m     cmd, shell\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      4\u001b[0m     stdout\u001b[38;5;241m=\u001b[39msubprocess\u001b[38;5;241m.\u001b[39mPIPE, stderr\u001b[38;5;241m=\u001b[39msubprocess\u001b[38;5;241m.\u001b[39mSTDOUT,\n\u001b[1;32m      5\u001b[0m     text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, bufsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      6\u001b[0m )\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m process\u001b[38;5;241m.\u001b[39mstdout:\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(line, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m process\u001b[38;5;241m.\u001b[39mwait()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 运行训练\n",
    "process = subprocess.Popen(\n",
    "    cmd, shell=True,\n",
    "    stdout=subprocess.PIPE, stderr=subprocess.STDOUT,\n",
    "    text=True, bufsize=1\n",
    ")\n",
    "for line in process.stdout:\n",
    "    print(line, end='')\n",
    "process.wait()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"返回码: {process.returncode}\")\n",
    "\n",
    "# 清理\n",
    "if os.path.exists(temp_config):\n",
    "    os.remove(temp_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 查看训练状态"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最新实验: experiments/ct_denoise_teacher_260102_175536\n",
      "Checkpoints: []\n",
      "\n",
      "最后 10 行日志:\n",
      "    ]\n",
      "    stage2_file: experiments/ct_denoise_teacher/stage2_matched.txt\n",
      "    distributed: False\n",
      "  \n",
      "  26-01-02 17:55:39.185 - INFO: CT dataset [ct] is created. Size: 3450\n",
      "  26-01-02 17:55:40.548 - INFO: CT dataset [ct] is created. Size: 0\n",
      "  26-01-02 17:55:40.549 - INFO: Initial Dataset Finished\n",
      "  26-01-02 17:55:42.574 - INFO: Initialization method [orthogonal]\n",
      "  26-01-02 17:55:43.374 - INFO: [DDM2] is created.\n",
      "  26-01-02 17:55:43.374 - INFO: Initial Model Finished\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "# 查找最新实验\n",
    "exp_dirs = sorted(glob.glob('experiments/*'), key=os.path.getmtime, reverse=True)\n",
    "\n",
    "if exp_dirs:\n",
    "    latest = exp_dirs[0]\n",
    "    print(f\"最新实验: {latest}\")\n",
    "    \n",
    "    # Checkpoints\n",
    "    ckpt_dir = f\"{latest}/checkpoint\"\n",
    "    if os.path.exists(ckpt_dir):\n",
    "        ckpts = sorted(os.listdir(ckpt_dir))\n",
    "        print(f\"Checkpoints: {ckpts}\")\n",
    "    \n",
    "    # 日志\n",
    "    logs = glob.glob(f\"{latest}/*.log\") + glob.glob(f\"{latest}/logs/*.log\")\n",
    "    if logs:\n",
    "        print(f\"\\n最后 10 行日志:\")\n",
    "        with open(logs[0], 'r') as f:\n",
    "            for line in f.readlines()[-10:]:\n",
    "                print(f\"  {line}\", end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 下一步\n",
    "\n",
    "训练完成后，使用 `3_inference/inference_ddm2.ipynb` 进行推理。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
